# Start of the target is January 1st 2017
start_target = datetime(year=2017, month=1, day=1)

# Select gifts made before start_target
gifts_before_2017 = gifts[gifts["date"] < start_target]

# Print the number of donations in gifts_before_2017
print(len(gifts_before_2017))

# Select the relevant predictors and the target
X = basetable[["amount_2017"]]
y = basetable[["target"]]

# Build the logistic regression model
logreg = linear_model.LogisticRegression()
logreg.fit(X, y)

# Make predictions for X
predictions = logreg.predict_proba(X)[:,1]

# Calculate and print the AUC value
auc = roc_auc_score(y, predictions)
print(round(auc, 2))

# Gifts made in 2013 or later
gifts_include = gifts[gifts["date"].dt.year >= 2013]

# Gifts made in 2017 or later
gifts_exclude = gifts[gifts["date"].dt.year >= 2017]

# Set with ids in gifts_include
donors_include = set(gifts_include["id"])

# Set with ids in gifts_exclude
donors_exclude = set(gifts_exclude["id"])

# Population
population = donors_include.difference(donors_exclude)
print(len(population))

# Create a dataframe donors_population
donors_population = donors[(donors["address"] == 1) & (donors["letter_allowed"] == 1)]

# Create a list of donor IDs
population_list = list(donors_population["donor_id"])

# Select unique donors in population_list
population = set(population_list)
print(len(population))


# Basetable with one column: donor_id
basetable = pd.DataFrame(population, columns=["donor_id"])

# Add target to the basetable
basetable["target"] = pd.Series([1 if donor_id in attend_event else 0 for donor_id in basetable["donor_id"]])

# Calculate and print the target incidence
print(round(basetable["target"].sum() / len(basetable), 2))

# Sum of donations for each donor in gifts_201701
gifts_summed = gifts_201701.groupby("id")["amount"].sum().reset_index()

# List with targets
targets = list(gifts_summed["id"][gifts_summed["amount"] > 50])

# Add targets to the basetable
basetable["target"] = pd.Series([1 if donor_id in targets else 0 for donor_id in basetable["donor_id"]])

# Calculate and print the target incidence
print(round(basetable["target"].sum() / len(basetable), 2))


# Reference date
reference_date = datetime.date(2017, 5, 1)

# Add age to the basetable
basetable["age"] = pd.Series([calculate_age(date_of_birth, reference_date)
                              for date_of_birth in basetable["date_of_birth"]])

# Calculate mean age
print(round(basetable["age"].mean()))

# Add the donor segment to the basetable
basetable = pd.merge(basetable, segments, on=["donor_id"], how="left")

# Count the number of donors in each segment
basetable.groupby("segment").size()

# Count the number of donors with no segment assigned
print(basetable["segment"].isna().sum())


# Reference date
reference_date = datetime.date(2017, 1, 1)

# Select living place reference date
living_places_reference_date = living_places[(living_places["start_date"] <= reference_date) & 
                                             (living_places["end_date"] > reference_date)]

# Add living place to the basetable
basetable = pd.merge(basetable, living_places_reference_date[["donor_ID", "living_place"]], on="donor_ID")

# Start and end date of the aggregation period
start_date = datetime.date(2017, 1, 1)
end_date = datetime.date(2017, 5, 1)

# Select gifts made in 2017
gifts_2017 = gifts[(gifts["date"] >= start_date) & (gifts["date"] < end_date)]

# Maximum gift per donor in 2017
gifts_2017_bydonor = gifts_2017.groupby(["id"])["amount"].max().reset_index()
gifts_2017_bydonor.columns = ["donor_ID", "max_amount"]

# Add maximum amount to the basetable
basetable = pd.merge(basetable, gifts_2017_bydonor)


# Reference date to calculate the recency
reference_date = datetime.date(2017, 5, 1)

# Select gifts made before the reference date
gifts_before_reference = gifts[(gifts["date"] < reference_date)]

# Latest gift per donor in 2017
last_gift = gifts_before_reference.groupby(["id"])["date"].max().reset_index()
last_gift["recency"] = reference_date - last_gift["date"]   

# Add recency to the basetable
basetable = pd.merge(basetable, last_gift[["id", "recency"]], how="left")

# Average gift last month and year for each donor
average_gift_last_month = gifts_last_month.groupby("id")["amount"].mean().reset_index()
average_gift_last_month.columns = ["donor_ID", "mean_gift_last_month"]

# Average gift last year for each donor
average_gift_last_year = gifts_last_year.groupby("id")["amount"].mean().reset_index()
average_gift_last_year.columns = ["donor_ID", "mean_gift_last_year"]

# Add average gift last month and year to basetable
basetable = pd.merge(basetable, average_gift_last_month, on="donor_ID", how="left")
basetable = pd.merge(basetable, average_gift_last_year, on="donor_ID", how="left")

# Calculate ratio of last month's and last year's average
basetable["ratio_month_year"] = basetable["mean_gift_last_month"] / basetable["mean_gift_last_year"]
print(basetable.head())

# Number of gifts in 2016 and 2017 for each donor
gifts_2016_bydonor = gifts_2016.groupby("id").size().reset_index()
gifts_2016_bydonor.columns = ["donor_ID", "donations_2016"]
gifts_2017_bydonor = gifts_2017.groupby("id").size().reset_index()
gifts_2017_bydonor.columns = ["donor_ID", "donations_2017"]

# Add number of gifts in 2016 and 2017 to the basetable
basetable = pd.merge(basetable, gifts_2016_bydonor, on="donor_ID", how="left")
basetable = pd.merge(basetable, gifts_2017_bydonor, on="donor_ID", how="left")

# Calculate the number of gifts in 2017 minus number of gifts in 2016
basetable.fillna(0)
basetable["gifts_2017_min_2016"] = basetable["donations_2017"] - basetable["donations_2016"]
print(basetable.head())

# Select the evolution variables and fit the model
X_evolution = basetable[variables_evolution]
logreg.fit(X_evolution, y)

# Make predictions and calculate the AUC
predictions_evolution = logreg.predict_proba(X_evolution)[:,1]
auc_evolution = roc_auc_score(y, predictions_evolution)

# Print the respective AUC values
print(round(auc_regular, 2))
print(round(auc_evolution, 2))

# Discretize the variable in 5 bins and add to the basetable
basetable["donations_2017_min_2016_disc"] = pd.qcut(basetable["donations_2017_min_2016"], 5)

# Construct the predictor insight graph table
pig_table = create_pig_table(basetable, "target", "donations_2017_min_2016_disc")

# Plot the predictor insight graph
plot_pig(pig_table, "donations_2017_min_2016_disc")

# Create the dummy variable
dummies_gender = pd.get_dummies(basetable["gender"], drop_first=True)

# Add the dummy variable to the basetable
basetable = pd.concat([basetable, dummies_gender], axis=1)

# Delete the original variable from the basetable
del basetable["gender"]
print(basetable.head())

# Create the dummy variable
dummies_country = pd.get_dummies(basetable["country"], drop_first=True)

# Add the dummy variable to the basetable
basetable = pd.concat([basetable, dummies_country], axis=1)

# Delete the original variable from the basetable
del basetable["country"]
print(basetable.head())# Create the dummy variable
dummies_country = pd.get_dummies(basetable["country"], drop_first=True)

# Add the dummy variable to the basetable
basetable = pd.concat([basetable, dummies_country], axis=1)

# Delete the original variable from the basetable
del basetable["country"]
print(basetable.head())

# Create dummy indicating missing values
basetable["no_donations"] = pd.Series([1 if b else 0 for b in basetable["total_donations"].isna()])

# Calculate number of missing values
number_na = sum(basetable["no_donations"] == 1)

# Calculate percentage of missing values
print(round(number_na / len(basetable), 2))

# Calculate the median of age
median_age = basetable["age"].median()
print(median_age)

# Replace missing values by the median
basetable["age"] = basetable["age"].fillna(median_age)

# Calculate the median of age after replacement
median_age = basetable["age"].median()
print(median_age)

# Missing values replacement
replacement = 0

# Replace missing values by the appropriate value
basetable["total_donations"] = basetable["total_donations"].fillna(replacement)

from scipy.stats.mstats import winsorize

# Check minimum sum of donations
print(basetable["sum_donations"].min())
print(basetable["sum_donations"].max())

# Fill out the lower limit
lower_limit = 0.0

# Winsorize the variable sum_donations
basetable["sum_donations_winsorized"] = winsorize(basetable["sum_donations"], limits=[lower_limit, 0.05])

# Check maximum sum of donations after winsorization
print(basetable["sum_donations_winsorized"].max())
